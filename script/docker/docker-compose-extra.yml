#
version: "3.2"
services:

  zookeeper:
    image: bitnami/zookeeper
    container_name: zookeeper
    restart: on-failure
    networks:
      - jwolf
    ports:
      - '2182:2181'
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
  #启动失败？删除data/meta.properties
  kafka:
    image: bitnami/kafka:2.6.0
    container_name: kafka
    user: root
    restart: always
    networks:
      - jwolf
    ports:
      - 9092:9092
    volumes:
      - /home/data/kafka:/bitnami/kafka
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://192.168.154.141:9092  #！！！！向外部暴露的地址！！！,即client端连接需走这个地址
      - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - zookeeper


  mongodb:
      image: mongo:4.1.2
      container_name: mongodb
      restart: on-failure
      environment:
          - MONGO_DATA_DIR=/data/db
          - MONGO_LOG_DIR=/data/logs
          - MONGO_INITDB_ROOT_USERNAME=admin
          - MONGO_INITDB_ROOT_PASSWORD=123456
      volumes:
          - /home/data/mongodb:/data/db
          - /var/log/mongodb:/data/logs
      ports:
          - 27017:27017

  jenkins:
    image: 'jenkins/jenkins:lts'
    container_name: jenkins
    restart: on-failure
    ports:
      - '8280:8080'
      - '50000:50000'
    volumes:
      - '/home/data/jenkins_home:/var/jenkins_home'
    networks:
      - jwolf



  rmqnamesrv:
    image: foxiswho/rocketmq:server
    container_name: rmqnamesrv
    restart: on-failure
    ports:
      - 9876:9876
    volumes:
      - /var/log/rocketmq:/opt/logs
      - /home/data/rocketmq:/opt/store
    networks:
        - jwolf
  rmqbroker:
    image: foxiswho/rocketmq:broker
    container_name: rmqbroker
    ports:
      - 10909:10909
      - 10911:10911
    volumes:
      - /var/log/rocketmq:/opt/logs
      - /home/data/rocketmq:/opt/store
      - /etc/rocketmq/broker.conf:/etc/rocketmq/broker.conf
    environment:
        NAMESRV_ADDR: "rmqnamesrv:9876"
        JAVA_OPTS: " -Duser.home=/opt"
        JAVA_OPT_EXT: "-server -Xms128m -Xmx128m -Xmn80m"
    command: mqbroker -c /etc/rocketmq/broker.conf
    depends_on:
      - rmqnamesrv
    networks:
      - jwolf
  rmqconsole:
    image: styletang/rocketmq-console-ng
    container_name: rmqconsole
    ports:
      - 9000:8080   #web控制台
    environment:
        JAVA_OPTS: "-Drocketmq.namesrv.addr=rmqnamesrv:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false"
    depends_on:
      - rmqnamesrv
    networks:
      - jwolf

  minio:
    image: minio/minio
    container_name: minio
    ports:
      - 19000:9000   #web控制台
      - 9001:9001   #web控制台
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ACCESS_KEY=admin
      - MINIO_SECRET_KEY=admin123456
    volumes:
      - /home/data/minio:/data
    networks:
      - jwolf

  clickhouse_server:
    image: yandex/clickhouse-server
    ports:
      - "8123:8123"
      - "29009:9009"
      - "29000:9000"
    environment:
      - ulimit="nofile=262144:262144"
    volumes:
      - /home/data/clickhouse:/var/lib/clickhouse:rw
      - /etc/clickhouse/users.xml:/etc/clickhouse-server/users.xml   #先不挂载配置启动copy容器的配置到宿主机docker cp clickhouse-server:/etc/clickhouse-server /etc/clickhouse，default用户增加密码123456，profile改为readonly,users节点新增root用户：
      - /etc/clickhouse/config.xml:/etc/clickhouse-server/config.xml
      - /var/log/clickhouse/log:/var/log/clickhouse-server:rw
    networks:
        - jwolf

#users.xml users节点新增的root用户如下，密码明文root,sha256_hex密码生成：echo -n root | sha256sum | tr -d '-'
#<root>
#         <password_sha256_hex>4813494d137e1631bba301d5acab6e7bb7aa74ce1185d456565ef51d737677b2</password_sha256_hex>
#         <networks incl="networks" replace="replace">
#                <ip>::/0</ip></networks>
#        <profile>default</profile>
#        <quota>default</quota>
#</root>
# idea datasourse插件连接clickhouse进行基本操作，基本操作类似mysql


# https://hub.docker.com/r/singularities/hadoop
#命令测试：进入namenode或datanode
#  hadoop fs -mkdir -p /hdfs/d1/d2
#  echo "hello hdfs" >>local.txt
#  hadoop fs -put local.txt /hdfs/d1/d2
# 该版本为2.8.3 spark连接时访问不了
  namenode:
    image: singularities/hadoop
    command: start-hadoop namenode
    hostname: namenode
    container_name: namenode
    environment:
      HDFS_USER: hdfsuser
    ports:
      - "8020:8020"
      - "14000:14000"
      - "50070:50070"   # web ui端口
      - "50075:50075"
      - "10020:10020"
      - "13562:13562"
      - "19888:19888"
    networks:
        - jwolf

  datanode:
    image: singularities/hadoop
    command: start-hadoop datanode namenode
    container_name: datanode
    environment:
      HDFS_USER: hdfsuser
    volumes:
      - /home/data/hadoop/hdfs:/opt/hdfs
    networks:
        - jwolf



networks:
  jwolf:
    driver: bridge

